

* [драфт ноутбука](./28_final_task/retail%20copy.ipynb)

# первичный анализ датасета
1. есть данные по возвратам
2. данные по названию товаров не выделены в группы
3. доля прочих клиентов не имеющих ID велика
4. каждая транзакция разбита отдельно по товарам в 1 покупке
5. есть отрицательные или 0 суммы в продажах они соответствуют возвратам
6. важно учитывать локацию продаж, так как наблюдается явная доля одной локации

Идеи и гипотезы:
1. всех пользователей которые без ID выделить в прочие, возможно или это недочеты датасета или прочие (иные каналы сбыта)
2. выделить долю транзакций в которых были сделаны возвраты (['все товары в заказе', 'частичный возврат'])
3. добавить фичи, выходные дни, дни недели, месяц, для возможности смены масштаба
4. доработать кластеризацию товаров, и выделить в них топ категорий для анализа или выделить топ категорий по сумме продаж, в разрезе каждой локации
5. после этого, делать более глубокий анализ сезонности продаж
6. далее делать прогноз продаж а так же долю возвратов
7. отдельно можно выделить частоту совершения транзакций для тех покупателей у которых есть ID, для учета данного прогноза в случае увеличения доли потребителей, может оказаться что покупатели совершают не регулярные покупки




выявить корреляцию между категориями товаров, влияющие на совместные покупки (1. совместное наличие товарных запасов 2. совместное позиционирование на витринах)
использовать GPT для катетеризации, далее использовать модель (соблюсти баланс между категориями, чтобы не было пересечения категорий)
другой моделью доразметить категории


///
Список хороших llm моделей с чатами, где можно будет попробовать разметку на категории для топ встречаемых товаров:
https://chat.openai.com/
https://gemini.google.com/app
https://www.perplexity.ai/?login-source=oneTapHome
https://claude.ai/new



## использованные инструменты
1. использовал разные модели и походы
  для ускорения применялись `cuda` 
  models = [
    'paraphrase-MiniLM-L6-v2',
    'all-MiniLM-L6-v2',
    'bert-base-uncased',
    'roberta-base',
    'distilbert-base-uncased'
  ]

  при этом на основании лучших показателей лучшей показала себя 
  Best model: paraphrase-MiniLM-L6-v2
  Best number of clusters (K): 10
  Best Silhouette Score: 0.08173604309558868

в итоге получилось 10 кластеров
[первые 20 вывел в файл](./28_final_task/clusters_4_top_20_per_cluster.txt)

2. на основании данный разметки сформировал [файл](./28_final_task/unique_descriptions_category.xlsx) для оценки качества 
  так же сделан перевод `ru` перевел позиций из кластеров на русский для оценки качества, при этом используя gatGPT придал смысл данным категориям

Безусловно есть смежность категорий и они близко расположены друг другу, думаю это обусловлено товарными позициями магазина, и замысловатостью названий категорий

3. так же попросил GPT [разметить первые 1000 позиций по категориям](./28_final_task/GPT_catalogcategory.txt), но не применял данную разметку для дообучения модели. по сути можно применить его разметку к остальным товарам.


4. построение графиков продаж и возвратов по каждой категории (для оценки наличия шума в данных по продажам)

///////
## **27 Модели ARMA**

### Задание

* **Цель:**
  * Прогнозирование спроса в онлайн ритейле

* **Шаги выполнения**

* анализ датасета
* определение ключевых фич
* препроцессинг данных
* построение моделей
* сохранение моделей
* вывод по результатам проделанной работы
/////////